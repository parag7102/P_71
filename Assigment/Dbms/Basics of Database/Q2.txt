2. What is Normalization?
Normalization is a process used in database design to organize data efficiently and minimize redundancy. It involves structuring a database into tables with well-defined relationships to reduce duplication of information and improve data integrity.

Here are some key aspects of Normalization:

Reduces Data Redundancy: By eliminating the need to store the same piece of data in multiple places, normalization saves storage space and minimizes the chance of inconsistencies arising from duplicated information.

Improves Data Integrity: Normalization ensures data is stored in a consistent and logical way. This makes it easier to maintain the accuracy of the data, as any updates only need to be made in one place.

Enhances Data Efficiency: A well-normalized database allows for faster data retrieval and manipulation. By organizing data efficiently, queries and other operations can be performed more quickly.

There are different levels of normalization, referred to as "normal forms." Each form has specific criteria that a database table needs to meet to be considered normalized. Common normal forms include:

First Normal Form (1NF): Eliminates repeating groups of data within a single table.
Second Normal Form (2NF): Ensures all columns depend on the entire primary key, not just a part of it.
Third Normal Form (3NF): Removes any columns that depend on non-key attributes (other than the primary key).
Normalization is a crucial concept for designing effective databases. It helps to streamline data organization, minimize errors, and ensure data integrity, leading to a more reliable and efficient database system.
